{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the import keyword to import pandas, requests, and bs4 modules\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the NY WARN notice url to a variable\n",
    "url = \"https://labor.ny.gov/app/warn/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define headers\n",
    "headers = {'accept-encoding': 'deflate'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a get request to the url using the requests library and assign the response to a variable called 'response'\n",
    "response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out status code of response to confirm that your request worked\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the response text using Beautiful Soup's html parser and assign output to a variable called 'soup'\n",
    "# response.text\n",
    "type(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape the first table on the page and assign it to a variable called 'table'\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab all rows from the table and assign to a variable called 'rows'\n",
    "table = soup.find(\"table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the number of rows â€” this is how many WARN notices there were in 2020 \n",
    "rows = soup.find_all(\"tr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an array called 'results'\n",
    "results = []\n",
    "# loop through the rows using a for loop\n",
    "for row in rows:\n",
    "    # grab the anchor tag (the link tag) in the row and then grab the href attribute from the tag\n",
    "    a = row.find(\"a\")['href']\n",
    "    \n",
    "    # concatenate the root url from above with this href attribute and assign to a variable called 'company_url'\n",
    "    company_url = f'{url}{a}'\n",
    "\n",
    "    # make a get request to the company url assign the response to a variable called 'company_response'\n",
    "    company_response = requests.get(company_url, headers=headers)\n",
    "    \n",
    "    # parse the response text and assign output to a variable called 'company_soup'\n",
    "    company_soup = BeautifulSoup(company_response.text, 'html.parser')\n",
    "    \n",
    "    # grab the first table on the page\n",
    "    company_table = company_soup.find(\"table\")\n",
    "    \n",
    "    # unwrap all of the spans\n",
    "    \n",
    "    # loop through all of the p tags\n",
    "    for p in company_table.find_all('p'):\n",
    "        text = p.get_text('\\n', strip=True)\n",
    "        if ('Date of Notice:' in text):\n",
    "            notice_date = text.split(\":\")[1].strip().split('\\n')[0].split()[0].replace(',', '').replace(';', '')\n",
    "            # print(notice_date)\n",
    "        elif ('Reason Stated for Filing:' in text):\n",
    "            reason = text.split(\":\")[1].strip()\n",
    "            # print(reason)\n",
    "        elif ('Company:' in text):\n",
    "            split_company = text.split('\\n')\n",
    "            company = split_company[1].strip()\n",
    "            address = \" \".join(split_company[2:])\n",
    "            #print(company)\n",
    "            #print(address)\n",
    "        elif ('Phone:' in text):\n",
    "            phone = text.split(\":\")[1].strip()\n",
    "            #print(phone)\n",
    "        elif ('Business Type:' in text):\n",
    "            business_type = text.split(\":\")[1].strip()\n",
    "            #print(business_type)\n",
    "        elif ('Number Affected:' in text):\n",
    "            affected = text.split(\":\")[1].strip().split()[0].replace(',', '')\n",
    "            #print(affected)\n",
    "        elif ('Total Employees:' in text):\n",
    "            total_employees = text.split(\":\")[1].strip().split()[0].replace(',', '')\n",
    "            #print(total_employees)\n",
    "        elif ('Layoff Date:' in text):\n",
    "            layoff_date = text.split(\":\")[1].strip()\n",
    "            #print(layoff_date)\n",
    "        elif ('Reason for Dislocation:' in text):\n",
    "            dislocation = text.split(\":\")[1].strip()\n",
    "            #print(dislocation)\n",
    "        elif ('Union:' in text):\n",
    "            union = text.split(\":\")[1].strip()\n",
    "            #print(union)\n",
    "        elif ('Classification:' in text):\n",
    "            classification = text.split(\":\")[1].strip()\n",
    "            #print(classification)\n",
    "    result = {\n",
    "        'notice_date': notice_date,\n",
    "        'reason': reason,\n",
    "        'company': company,\n",
    "        'address': address,\n",
    "        'phone': phone,\n",
    "        'business_type': business_type,\n",
    "        'affected': affected,\n",
    "        'total_employees': total_employees,\n",
    "        'layoff_date': layoff_date,\n",
    "        'dislocation': dislocation,\n",
    "        'union': union,\n",
    "        'classification': classification\n",
    "     }\n",
    "    \n",
    "    # append result object to reusults\n",
    "    results.append(result)    \n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap results in a dataframe\n",
    "dt = pd.DataFrame(results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dataframe to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
